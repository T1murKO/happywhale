{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "from torchvision import transforms as T\n",
    "import numpy as np\n",
    "from imgaug.augmenters import Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop(Augmenter):\n",
    "    def __init__(self, box_csv, extend_share=(0,1), name=None, deterministic=False, random_state=None):\n",
    "        super(Crop, self).__init__(name=name, deterministic=deterministic, random_state=random_state)\n",
    "        self.box_csv = \n",
    "        \n",
    "\n",
    "    def _augment_images(self, images, random_state, parents, hooks):\n",
    "        for i in range(nb_images):\n",
    "            if samples[i] == 1:\n",
    "                images[i] = np.fliplr(images[i])\n",
    "        return images\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img):\n",
    "    return img[:50,:50,:]\n",
    "\n",
    "def func_images(images, random_state, parents, hooks):\n",
    "    images = [crop_img(images[i]) for i in range(len(images))]\n",
    "    return images\n",
    "    \n",
    "def func_heatmaps(heatmaps, random_state, parents, hooks):\n",
    "    return heatmaps\n",
    "    \n",
    "def func_keypoints(keypoints_on_images, random_state, parents, hooks):\n",
    "    return keypoints_on_images\n",
    "\n",
    "crop_augmenter = iaa.Lambda(\n",
    "    func_images=func_images,\n",
    ")\n",
    "\n",
    "aug = iaa.Sequential([iaa.Fliplr(0.5), crop_augmenter(d=1), iaa.Sometimes(0.2, iaa.AverageBlur(k=(3,3)))]).augment_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.rand(100, 100, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ = aug(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv('/root/kaggle/submission2/test_neighbors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s.target != '37c7aba965a5']['image'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a479fee58ddad8d5776fa539da594c69e29ceaa4b5647eb25d0dd86d97628ab7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('whale_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
