{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TPU has started up successfully with version pytorch-1.9\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import efficientnet_b0\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn, optim \n",
    "import math\n",
    "import imgaug.augmenters as iaa\n",
    "from random import randint, sample\n",
    "\n",
    "from PIL.Image import fromarray\n",
    "import cv2\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os.path import join\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import json\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.utils.utils as xu\n",
    "\n",
    "device = xm.xla_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaCos(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes, fixed_scale=False):\n",
    "        super(AdaCos, self).__init__()\n",
    "        self.fixed_scale = fixed_scale\n",
    "        self.scale = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self.W = nn.Parameter(torch.FloatTensor(num_classes, feat_dim))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "        \n",
    "    def forward(self, feats, labels):\n",
    "        W = F.normalize(self.W)\n",
    "\n",
    "        logits = F.linear(feats, W)\n",
    "\n",
    "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        one_hot = torch.zeros_like(logits)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "\n",
    "        if self.fixed_scale:\n",
    "            with torch.no_grad():\n",
    "                B_avg = torch.where(one_hot < 1, torch.exp(self.scale * logits), torch.zeros_like(logits))\n",
    "                B_avg = torch.sum(B_avg) / feats.size(0)\n",
    "                \n",
    "                theta_med = torch.median(theta[one_hot == 1])\n",
    "                self.scale = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "            \n",
    "        output = self.scale * logits\n",
    "        return output\n",
    "    \n",
    "    def get_logits(self, feats):\n",
    "        W = F.normalize(self.W)\n",
    "\n",
    "        logits = F.linear(feats, W)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM,self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "                \n",
    "        self.backbone = torch.nn.Sequential(*(list(efficientnet_b0(pretrained=True).children())[:-2]))\n",
    "        self.gem_pool = GeM()\n",
    "        self.bn1 = nn.BatchNorm1d(1280)\n",
    "        self.fc1 = nn.Linear(1280, 512)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.arc_face = AdaCos(512, num_classes)\n",
    "        \n",
    "    def forward(self, x, targets = None):\n",
    "        x = torch.squeeze(torch.squeeze(self.gem_pool(self.backbone(x)), -1), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(self.dropout(self.bn1(x))))\n",
    "        x = F.normalize(x)\n",
    "        \n",
    "        if targets is not None:\n",
    "            logits = self.arc_face(x, targets)\n",
    "            return logits\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def get_logits(self, x):\n",
    "        x = self.gem_pool(self.backbone(x))\n",
    "        x = torch.unsqueeze(torch.squeeze(x), 0)\n",
    "        x = F.relu(self.fc1(self.dropout(self.bn1(x))))\n",
    "        x = F.normalize(x)\n",
    "\n",
    "        logits = self.arc_face.get_logits(x)\n",
    "        return logits\n",
    "        \n",
    "input_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = join('/content/happywhale/data/train.csv')\n",
    "img_data = join('/content/train_images-256-256')\n",
    "data_csv = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, csv, img_folder, transform=None):\n",
    "    self.transform = transform\n",
    "    self.img_folder = img_folder\n",
    "     \n",
    "    self.images = csv['image']\n",
    "    self.targets = csv['Y']\n",
    "   \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    " \n",
    "\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    image = cv2.cvtColor(cv2.imread(join(self.img_folder, self.images[index])), cv2.COLOR_BGR2RGB)\n",
    "    target = self.targets[index]\n",
    "     \n",
    "    if self.transform is not None:\n",
    "        image = self.transform(image)\n",
    "    \n",
    "    return image, target\n",
    "\n",
    "\n",
    "transforms_list = T.Compose([             \n",
    "    iaa.Sequential([\n",
    "        iaa.Sequential([\n",
    "        iaa.Sometimes(0.3, iaa.AverageBlur(k=(3,3))),\n",
    "        iaa.Sometimes(0.3, iaa.MotionBlur(k=(3,5))),\n",
    "        iaa.Add((-10, 10), per_channel=0.5),\n",
    "        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "        iaa.Sometimes(0.3, iaa.Affine(\n",
    "            scale={'x': (0.9,1.1), 'y': (0.9,1.1)},\n",
    "            translate_percent={'x': (-0.05,0.05), 'y': (-0.05,0.05)},\n",
    "            shear=(-10,10),\n",
    "            rotate=(-10,10)\n",
    "            )),\n",
    "        iaa.Sometimes(0.3, iaa.Grayscale(alpha=(0.8,1.0))),\n",
    "        ], random_order=True),\n",
    "        iaa.size.Resize(input_size, interpolation='cubic')\n",
    "    ]).augment_image,     \n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(data_csv,\n",
    "                             img_data,\n",
    "                             transform=transforms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15587"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv['individual_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "start_epoch = 0\n",
    "num_epochs = 10\n",
    "lr = 0.0001\n",
    "# schedule = [0.001, 0.00075, 0.0005]\n",
    "num_classes = 15587\n",
    "# save_path = join(pwd, '../models/renet_50')\n",
    "lr_start   = 0.000001\n",
    "lr_max     = 0.000005 * batch_size\n",
    "lr_min     = 0.000001\n",
    "lr_ramp_ep = 4\n",
    "lr_sus_ep  = 0\n",
    "lr_decay   = 0.9\n",
    "\n",
    "num_workers = 1\n",
    "num_cores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "FLAGS = {}\n",
    "FLAGS['batch_size'] = 32\n",
    "FLAGS['num_workers'] = 1\n",
    "FLAGS['learning_rate'] = 0.0001\n",
    "FLAGS['num_epochs'] = 10\n",
    "FLAGS['num_cores'] = 8\n",
    "FLAGS['log_steps'] = 10\n",
    "FLAGS['data_csv_path'] = '/content/happywhale/data/train.csv'\n",
    "FLAGS['images_path'] = '/content/train_images-256-256'\n",
    "FLAGS['input_size'] = input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERIAL_EXEC = xmp.MpSerialExecutor()\n",
    "\n",
    "\n",
    "\n",
    "# Only instantiate model weights once in memory.\n",
    "WRAPPED_MODEL = xmp.MpModelWrapper(Net(num_classes=15587))\n",
    "\n",
    "def train_mnist():\n",
    "\n",
    "\n",
    "  torch.manual_seed(1)\n",
    "  \n",
    "  def get_dataset():\n",
    "    data_csv = pd.read_csv(FLAGS['data_csv_path'])\n",
    "\n",
    "    class ImageDataset(Dataset):\n",
    "      def __init__(self, csv, img_folder, transform=None):\n",
    "        self.transform = transform\n",
    "        self.img_folder = img_folder\n",
    "        \n",
    "        self.images = csv['image']\n",
    "        self.targets = csv['Y']\n",
    "      \n",
    "\n",
    "      def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "      def __getitem__(self, index):\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(join(self.img_folder, self.images[index])), cv2.COLOR_BGR2RGB)\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "\n",
    "    transforms_list = T.Compose([             \n",
    "        iaa.Sequential([\n",
    "            iaa.Sequential([\n",
    "            iaa.Sometimes(0.3, iaa.AverageBlur(k=(3,3))),\n",
    "            iaa.Sometimes(0.3, iaa.MotionBlur(k=(3,5))),\n",
    "            iaa.Add((-10, 10), per_channel=0.5),\n",
    "            iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
    "            iaa.Sometimes(0.3, iaa.Affine(\n",
    "                scale={'x': (0.9,1.1), 'y': (0.9,1.1)},\n",
    "                translate_percent={'x': (-0.05,0.05), 'y': (-0.05,0.05)},\n",
    "                shear=(-10,10),\n",
    "                rotate=(-10,10)\n",
    "                )),\n",
    "            iaa.Sometimes(0.3, iaa.Grayscale(alpha=(0.8,1.0))),\n",
    "            ], random_order=True),\n",
    "            iaa.size.Resize(FLAGS['input_size'], interpolation='cubic')\n",
    "        ]).augment_image,     \n",
    "        T.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageDataset(data_csv,\n",
    "                             FLAGS['images_path'],\n",
    "                             transform=transforms_list)\n",
    "    \n",
    "    return train_dataset\n",
    "  \n",
    "  # Using the serial executor avoids multiple processes to\n",
    "  # download the same data.\n",
    "  train_dataset = SERIAL_EXEC.run(get_dataset)\n",
    "\n",
    "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    train_dataset,\n",
    "    num_replicas=xm.xrt_world_size(),\n",
    "    rank=xm.get_ordinal(),\n",
    "    shuffle=True)\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "      train_dataset,\n",
    "      batch_size=FLAGS['batch_size'],\n",
    "      sampler=train_sampler,\n",
    "      num_workers=FLAGS['num_workers'],\n",
    "      drop_last=True)\n",
    "\n",
    "  # Scale learning rate to world size\n",
    "  lr = FLAGS['learning_rate'] * xm.xrt_world_size()\n",
    "\n",
    "  # Get loss function, optimizer, and model\n",
    "  device = xm.xla_device()\n",
    "  model = WRAPPED_MODEL.to(device)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  def train_loop_fn(loader):\n",
    "    tracker = xm.RateTracker()\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    pbar_train = tqdm(train_loader, desc=\"Epoch\" + \" [TRAIN] \" + str(1))\n",
    "    batch_num = len(pbar_train)\n",
    "    for it, (images, labels) in enumerate(pbar_train):\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      logits = model(images, labels)\n",
    "      loss = criterion(logits, labels)\n",
    "      loss.backward()\n",
    "      xm.optimizer_step(optimizer)\n",
    "      tracker.add(batch_size)\n",
    "      if it % 10 == 9:\n",
    "        print('[xla:{}]({}) Loss={:.5f} Rate={:.2f} GlobalRate={:.2f} Time={}'.format(\n",
    "            xm.get_ordinal(), it, loss.item(), tracker.rate(),\n",
    "            tracker.global_rate(), time.asctime()), flush=True)\n",
    "\n",
    "  # def test_loop_fn(loader):\n",
    "  #   total_samples = 0\n",
    "  #   correct = 0\n",
    "  #   model.eval()\n",
    "  #   data, pred, target = None, None, None\n",
    "  #   for data, target in loader:\n",
    "  #     output = model(data)\n",
    "  #     pred = output.max(1, keepdim=True)[1]\n",
    "  #     correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "  #     total_samples += data.size()[0]\n",
    "\n",
    "  #   accuracy = 100.0 * correct / total_samples\n",
    "  #   print('[xla:{}] Accuracy={:.2f}%'.format(\n",
    "  #       xm.get_ordinal(), accuracy), flush=True)\n",
    "  #   return accuracy, data, pred, target\n",
    "\n",
    "  # Train and eval loops\n",
    "  accuracy = 0.0\n",
    "  data, pred, target = None, None, None\n",
    "  for epoch in range(1, FLAGS['num_epochs'] + 1):\n",
    "    para_loader = pl.ParallelLoader(train_loader, [device])\n",
    "    train_loop_fn(para_loader.per_device_loader(device))\n",
    "    xm.master_print(\"Finished training epoch {}\".format(epoch))\n",
    "\n",
    "    # para_loader = pl.ParallelLoader(test_loader, [device])\n",
    "    # accuracy, data, pred, target  = test_loop_fn(para_loader.per_device_loader(device))\n",
    "    # if FLAGS['metrics_debug']:\n",
    "      # xm.master_print(met.metrics_report(), flush=True)\n",
    "\n",
    "  return accuracy, data, pred, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3796fab1c1954c8487c73d198b17352c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch [TRAIN] 1:   0%|          | 0/1594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "  global FLAGS\n",
    "  FLAGS = flags\n",
    "  torch.set_default_tensor_type('torch.FloatTensor')\n",
    "  accuracy, data, pred, target = train_mnist()\n",
    "  # if rank == 0:\n",
    "    # Retrieve tensors that are on TPU core 0 and plot.\n",
    "    # plot_results(data.cpu(), pred.cpu(), target.cpu())\n",
    "\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1,\n",
    "          start_method='fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
